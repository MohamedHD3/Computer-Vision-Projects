{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b080c83",
   "metadata": {},
   "source": [
    "# first project motion detection\n",
    "\n",
    "### if you watch previous tutorials you will understand what is happening behind syntax briefly, first step, movement is difference between two frames second, difference has noises because of details and light on video so gaussian blurring is eliminating the noises, third, obtaining threshold from clean difference fourth, dilating for eliminating district small weak threshold lines which corrupt healthy threshold detection fifth, finding contours from clean threshold sixth, eliminating small contours which can not be a human by filtering contour area seventh, drawing rectangles for each detected contour on the frame, rectangle dimensions obtained from cv2.boundingRect(contour) that is it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1da7732",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "048eb0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(576, 768, 3)\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('vtest.avi')\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc('X', 'V', 'I', 'D')\n",
    "out = cv2.VideoWriter('out.avi', fourcc, 30, (1280,720))\n",
    "\n",
    "ret, frame1 = cap.read()\n",
    "ret, frame2 = cap.read()\n",
    "print(frame1.shape)\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    diff = cv2.absdiff(frame1, frame2)\n",
    "    gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    blur = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "    \n",
    "    _, threshold = cv2.threshold(blur, 60, 255, cv2.THRESH_BINARY)\n",
    "    dilated = cv2.dilate(threshold, None, iterations=3)        \n",
    "    contours, _ = cv2.findContours(dilated, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)        \n",
    "#     draw = cv2.drawContours(frame1, contours, -1, (0,255,0), 2)\n",
    "\n",
    "    for contour in contours:        \n",
    "        (x, y, w, h) =  cv2.boundingRect(contour)             \n",
    "        if cv2.contourArea(contour) < 500:\n",
    "            continue\n",
    "        cv2.rectangle(frame1, (x, y), (x+w, y+h), (0,255,0), 2)\n",
    "        cv2.putText(frame1, 'Status: {}'.format('Movement'), (10,20),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 3)\n",
    "    \n",
    "        img = cv2.resize(frame1, (1280,720))\n",
    "        out.write(img)\n",
    "        cv2.imshow('Motion Detection', frame1)\n",
    "#         cv2.imshow('threshold', threshold)\n",
    "#         cv2.imshow('dilated', dilated)\n",
    "#         cv2.imshow('draw', draw)\n",
    "    \n",
    "    frame1 = frame2 # to take all frames in video\n",
    "    ret, frame2 = cap.read()\n",
    "    if cv2.waitKey(60) == 27:\n",
    "        break\n",
    "    \n",
    "cv2.destroyAllWindows() # close window\n",
    "\n",
    "cap.release() # close camera\n",
    "\n",
    "out.release() # close when write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aff11a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
